# TP01 - Architecture Interne de Kubernetes

## üéØ Objectifs p√©dagogiques

√Ä la fin de ce TP, vous serez capable de :
- Comprendre l'architecture des composants du control plane
- Analyser le fonctionnement de etcd et sa structure de donn√©es
- Observer les communications entre les composants
- D√©bugger un cluster Kubernetes
- Identifier les points de d√©faillance et leur impact

## üìö Pr√©requis

- Cluster Kubernetes fonctionnel (minikube, kind ou k3s)
- kubectl install√© et configur√©
- Acc√®s SSH aux nodes (pour minikube/kind)
- crictl install√©
- etcdctl install√©

## ‚è±Ô∏è Dur√©e estim√©e

3-4 heures

## üìã Partie 1 : Architecture du Control Plane

### 1.1 - Identifier les composants

```bash
# Lister tous les pods du control plane
kubectl get pods -n kube-system

# Observer les composants statiques
kubectl get pods -n kube-system -l tier=control-plane

# Examiner les logs de l'API server
kubectl logs -n kube-system kube-apiserver-<node-name>
```

**Questions :**
1. Quels sont les composants critiques du control plane ?
2. Combien d'instances de chaque composant avez-vous ?
3. Comment ces composants communiquent-ils entre eux ?

### 1.2 - Analyser l'API Server

```bash
# Voir la configuration de l'API server
kubectl get pod -n kube-system kube-apiserver-<node> -o yaml

# Identifier les flags de d√©marrage
kubectl describe pod -n kube-system kube-apiserver-<node>

# Tester l'API directement
kubectl proxy --port=8080 &
curl http://localhost:8080/api/v1/namespaces
```

**Exercice :**
- Identifiez le port d'√©coute de l'API server
- Trouvez o√π sont stock√©s les certificats TLS
- Listez les API groups disponibles

### 1.3 - Observer le Scheduler

```bash
# Logs du scheduler
kubectl logs -n kube-system kube-scheduler-<node>

# Cr√©er un pod avec des contraintes
kubectl apply -f pod-with-constraints.yaml

# Observer le scheduling
kubectl get events --sort-by='.lastTimestamp'
```

**Exercice :**
Cr√©ez un pod qui ne peut pas √™tre schedul√© et analysez pourquoi.

### 1.4 - Controller Manager

```bash
# Observer les controllers actifs
kubectl get pods -n kube-system | grep controller-manager

# Logs du controller manager
kubectl logs -n kube-system kube-controller-manager-<node>

# Lister les controllers
kubectl logs -n kube-system kube-controller-manager-<node> | grep "Starting"
```

**Questions :**
1. Combien de controllers sont actifs ?
2. Quel est le r√¥le du replication controller ?
3. Comment fonctionne le endpoint controller ?

## üìã Partie 2 : √âtude de etcd

### 2.1 - Connexion √† etcd

```bash
# Pour minikube
minikube ssh
sudo su -

# Installer etcdctl si n√©cessaire
ETCD_VER=v3.5.9
wget https://github.com/etcd-io/etcd/releases/download/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz
tar xzf etcd-${ETCD_VER}-linux-amd64.tar.gz
sudo mv etcd-${ETCD_VER}-linux-amd64/etcdctl /usr/local/bin/

# Exporter les variables d'environnement
export ETCDCTL_API=3
export ETCDCTL_CACERT=/var/lib/minikube/certs/etcd/ca.crt
export ETCDCTL_CERT=/var/lib/minikube/certs/etcd/server.crt
export ETCDCTL_KEY=/var/lib/minikube/certs/etcd/server.key

# V√©rifier la sant√©
etcdctl endpoint health
```

### 2.2 - Explorer les donn√©es

```bash
# Lister toutes les cl√©s
etcdctl get / --prefix --keys-only

# Voir les namespaces
etcdctl get /registry/namespaces --prefix --keys-only

# Examiner un pod
etcdctl get /registry/pods/default/<pod-name>

# Compter les objets
etcdctl get /registry --prefix --keys-only | wc -l
```

**Exercice :**
1. Trouvez o√π sont stock√©s les secrets
2. Examinez la structure d'un deployment
3. Identifiez les donn√©es des ConfigMaps

### 2.3 - Backup et Restore de etcd

```bash
# Cr√©er un backup
etcdctl snapshot save /tmp/etcd-backup.db

# V√©rifier le backup
etcdctl snapshot status /tmp/etcd-backup.db

# Simuler une perte de donn√©es
kubectl delete namespace test-backup

# Restore (ATTENTION: en production, proc√©dure plus complexe)
etcdctl snapshot restore /tmp/etcd-backup.db
```

## üìã Partie 3 : Communications entre composants

### 3.1 - Observer le flux de cr√©ation d'un Pod

```bash
# Activer le verbosity
kubectl apply -f test-pod.yaml -v=8

# Observer les events
kubectl get events -w &

# Cr√©er un pod
kubectl run debug-pod --image=nginx

# Analyser les logs
kubectl logs -n kube-system kube-apiserver-<node> | grep debug-pod
kubectl logs -n kube-system kube-scheduler-<node> | grep debug-pod
kubectl logs -n kube-system kube-controller-manager-<node> | grep debug-pod
```

**Questions :**
1. Quel composant re√ßoit la requ√™te en premier ?
2. Comment le scheduler est-il notifi√© ?
3. Quel est le r√¥le du kubelet dans ce processus ?

### 3.2 - Watch API

```bash
# Observer les changements en temps r√©el
kubectl get pods -w &

# Utiliser l'API directement
curl -v http://localhost:8080/api/v1/namespaces/default/pods?watch=true
```

## üìã Partie 4 : Debugging avanc√©

### 4.1 - Utiliser crictl

```bash
# Lister les containers via CRI
crictl ps

# Inspecter un container
crictl inspect <container-id>

# Logs via crictl
crictl logs <container-id>

# Stats des containers
crictl stats
```

### 4.2 - Analyser les probl√®mes de r√©seau

```bash
# V√©rifier les endpoints
kubectl get endpoints

# Tester la r√©solution DNS
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup kubernetes.default

# Examiner les iptables
# (sur le node)
sudo iptables-save | grep <service-name>
```

### 4.3 - Performance du Control Plane

```bash
# M√©triques de l'API server
kubectl get --raw /metrics | grep apiserver_request_duration

# M√©triques de etcd
kubectl get --raw /metrics | grep etcd_

# Latency de l'API
kubectl get pods --v=6 2>&1 | grep "Request duration"
```

## üìã Partie 5 : Sc√©narios de d√©faillance

### 5.1 - Simuler une panne de l'API Server

```bash
# Arr√™ter l'API server (minikube)
minikube ssh
sudo mv /etc/kubernetes/manifests/kube-apiserver.yaml /tmp/

# Observer l'impact
kubectl get pods  # Doit √©chouer

# Restaurer
sudo mv /tmp/kube-apiserver.yaml /etc/kubernetes/manifests/
```

**Questions :**
- Que se passe-t-il pour les pods en cours d'ex√©cution ?
- Les services sont-ils affect√©s ?
- Combien de temps pour la r√©cup√©ration ?

### 5.2 - Panne du Scheduler

```bash
# D√©sactiver le scheduler
kubectl scale deployment kube-scheduler -n kube-system --replicas=0

# Tenter de cr√©er un pod
kubectl run test --image=nginx

# Observer
kubectl get pods
kubectl describe pod test
```

### 5.3 - Panne de etcd

```bash
# ATTENTION: Tr√®s destructif, uniquement en environnement de test
# Simuler une corruption
# Observer la r√©cup√©ration automatique ou restaurer depuis backup
```

## üéì Exercices avanc√©s

### Exercice 1 : Audit complet
Cr√©ez un script qui g√©n√®re un rapport complet sur :
- L'√©tat de sant√© de tous les composants
- Les m√©triques de performance
- Les alertes potentielles

### Exercice 2 : Custom Scheduler
Comprenez comment fonctionnent les schedulers et pr√©parez-vous au TP15 sur les custom schedulers.

### Exercice 3 : Monitoring du Control Plane
Configurez Prometheus pour monitorer les m√©triques du control plane.

## üîç Points cl√©s √† retenir

1. **API Server** : Point d'entr√©e unique, tous les composants communiquent via lui
2. **etcd** : Source de v√©rit√©, critique pour le cluster
3. **Scheduler** : D√©cisions d'affectation bas√©es sur les ressources et contraintes
4. **Controller Manager** : Boucles de r√©conciliation pour maintenir l'√©tat d√©sir√©
5. **Kubelet** : Agent sur chaque node, interface avec le container runtime

## üìö Ressources compl√©mentaires

- [Kubernetes Components](https://kubernetes.io/docs/concepts/overview/components/)
- [etcd Documentation](https://etcd.io/docs/)
- [Kubernetes Architecture](https://kubernetes.io/docs/concepts/architecture/)
- [Debugging Kubernetes](https://kubernetes.io/docs/tasks/debug/)

## ‚úÖ Validation

Vous avez termin√© ce TP si vous pouvez :
- [ ] Expliquer le r√¥le de chaque composant du control plane
- [ ] Naviguer dans etcd et comprendre la structure des donn√©es
- [ ] Tracer le flux de cr√©ation d'une ressource
- [ ] Debugger des probl√®mes au niveau du control plane
- [ ] Simuler et r√©soudre des pannes de composants

## üöÄ Prochaine √©tape

TP02 - Networking Avanc√© et CNI
